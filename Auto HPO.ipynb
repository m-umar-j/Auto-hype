{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4108b4cb",
   "metadata": {},
   "source": [
    "## Auto HPO from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef7f060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>GeneticRisk</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>AlcoholIntake</th>\n",
       "      <th>CancerHistory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>16.085313</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.146251</td>\n",
       "      <td>4.148219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>30.828784</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.361630</td>\n",
       "      <td>3.519683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>38.785084</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.135179</td>\n",
       "      <td>4.728368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>30.040296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.502792</td>\n",
       "      <td>2.044636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>35.479721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.356890</td>\n",
       "      <td>3.309849</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>25.090025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.892167</td>\n",
       "      <td>1.284158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>33.447125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.668297</td>\n",
       "      <td>2.280636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>32.613861</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.466848</td>\n",
       "      <td>0.150101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>25.568216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.795317</td>\n",
       "      <td>1.986138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>23.663104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525860</td>\n",
       "      <td>2.856600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Gender        BMI  Smoking  GeneticRisk  PhysicalActivity  \\\n",
       "0      58       1  16.085313        0            1          8.146251   \n",
       "1      71       0  30.828784        0            1          9.361630   \n",
       "2      48       1  38.785084        0            2          5.135179   \n",
       "3      34       0  30.040296        0            0          9.502792   \n",
       "4      62       1  35.479721        0            0          5.356890   \n",
       "...   ...     ...        ...      ...          ...               ...   \n",
       "1495   62       1  25.090025        0            0          9.892167   \n",
       "1496   31       0  33.447125        0            1          1.668297   \n",
       "1497   63       1  32.613861        1            1          0.466848   \n",
       "1498   55       0  25.568216        0            0          7.795317   \n",
       "1499   67       1  23.663104        0            0          2.525860   \n",
       "\n",
       "      AlcoholIntake  CancerHistory  \n",
       "0          4.148219              1  \n",
       "1          3.519683              0  \n",
       "2          4.728368              0  \n",
       "3          2.044636              0  \n",
       "4          3.309849              0  \n",
       "...             ...            ...  \n",
       "1495       1.284158              0  \n",
       "1496       2.280636              1  \n",
       "1497       0.150101              0  \n",
       "1498       1.986138              1  \n",
       "1499       2.856600              1  \n",
       "\n",
       "[1500 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\Abuba\\Downloads\\The_Cancer_data_1500_V2.csv\")\n",
    "Y = df['Diagnosis']\n",
    "X = df.drop(columns=df.columns[-1])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46c76c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fb7d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter space\n",
    "space = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma = 'auto', probability = True),\n",
    "        'params': {\n",
    "            'C': [0.1, 0.5, 1, 5, 10],\n",
    "            'kernel': ['rbf', 'linear', 'sigmoid'],\n",
    "            'gamma': ['scale', 'auto'],\n",
    "            'degree': [2, 3, 4, 5]\n",
    "        }\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "            'max_depth': [5, 10, 15, 20],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 5, 10]\n",
    "    }\n",
    "    },\n",
    "    'logistic_regression': {\n",
    "        'model': LogisticRegression(solver = 'liblinear',multi_class='ovr'),\n",
    "        'params': {\n",
    "            'C' : [0.1, 0.5, 1, 5, 10],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'max_iter': [100, 500, 1000]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2bc5f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a620b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_val_auc(model, X, y, cv_splits=5):\n",
    "    cv = StratifiedKFold(n_splits=cv_splits)\n",
    "    auc_scores = []\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_train_cv, X_val_cv = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_cv, y_val_cv = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "        y_prob = model.predict_proba(X_val_cv)[:, 1]  # Probability of positive class\n",
    "\n",
    "        auc = roc_auc_score(y_val_cv, y_prob)\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "    return np.array(auc_scores)\n",
    "def objective_function(config, algo, X_train, Y_train):\n",
    "    model = space[algo]['model']\n",
    "    model.set_params(**config)\n",
    "    auc_scores = custom_cross_val_auc(model, X_train, Y_train, cv_splits=5)\n",
    "    mean_auc_score = np.mean(auc_scores)\n",
    "    return mean_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "83d7bee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 1/30\n",
      "Trial: 2/30\n",
      "Trial: 3/30\n",
      "Trial: 4/30\n",
      "Trial: 5/30\n",
      "Trial: 6/30\n",
      "Trial: 7/30\n",
      "Trial: 8/30\n",
      "Trial: 9/30\n",
      "Trial: 10/30\n",
      "Trial: 11/30\n",
      "Trial: 12/30\n",
      "Trial: 13/30\n",
      "Trial: 14/30\n",
      "Trial: 15/30\n",
      "Trial: 16/30\n",
      "Trial: 17/30\n",
      "Trial: 18/30\n",
      "Trial: 19/30\n",
      "Trial: 20/30\n",
      "Trial: 21/30\n",
      "Trial: 22/30\n",
      "Trial: 23/30\n",
      "Trial: 24/30\n",
      "Trial: 25/30\n",
      "Trial: 26/30\n",
      "Trial: 27/30\n",
      "Trial: 28/30\n",
      "Trial: 29/30\n",
      "Trial: 30/30\n"
     ]
    }
   ],
   "source": [
    "observations = []\n",
    "\n",
    "algorithms = list(space.keys())\n",
    "\n",
    "for i in range(30):# initial HP config\n",
    "    print(f\"Trial: {i+1}/30\")\n",
    "    algo = random.choice(algorithms)\n",
    "    if algo == 'svm':\n",
    "        hyperparams = {\n",
    "            'model': svm.SVC(gamma = 'auto', probability=True),\n",
    "            'params': {\n",
    "                'C': random.choice(space[algo]['params']['C']),\n",
    "                'kernel': random.choice(space[algo]['params']['kernel']),\n",
    "                'gamma': random.choice(space[algo]['params']['gamma']),\n",
    "                'degree': np.random.choice(space[algo]['params']['degree'])\n",
    "            }\n",
    "        }\n",
    "    elif algo == 'random_forest':\n",
    "        hyperparams = {\n",
    "            'model': RandomForestClassifier(),\n",
    "            'params': {\n",
    "                'n_estimators': random.choice(space[algo]['params']['n_estimators']),\n",
    "                'max_depth': (random.choice(space[algo]['params']['max_depth'])),\n",
    "                'min_samples_split': random.choice(space[algo]['params']['min_samples_split']),\n",
    "                'min_samples_leaf': random.choice(space[algo]['params']['min_samples_leaf'])\n",
    "                }\n",
    "            }\n",
    "    elif algo == 'logistic_regression':\n",
    "        hyperparams = {\n",
    "        'model': LogisticRegression(solver = 'liblinear'),\n",
    "        'params': {\n",
    "            'C' : random.choice(space[algo]['params']['C']),\n",
    "            'penalty': random.choice(space[algo]['params']['penalty']),\n",
    "            'max_iter': random.choice(space[algo]['params']['max_iter'])\n",
    "            }\n",
    "        }\n",
    "    #print(hyperparams)\n",
    "    # Evaluate the objective function for these hyperparameters\n",
    "    score = objective_function(hyperparams['params'], algo, X_train, Y_train)\n",
    "    # Add the observation to the list\n",
    "    observations.append((hyperparams, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed62ccd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'model': LogisticRegression(solver='liblinear'),\n",
       "   'params': {'C': 1, 'penalty': 'l1', 'max_iter': 100}},\n",
       "  0.9082723323908029),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 1, 'kernel': 'sigmoid', 'gamma': 'scale', 'degree': 3}},\n",
       "  0.5066928414088682),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 5, 'kernel': 'linear', 'gamma': 'scale', 'degree': 3}},\n",
       "  0.9085785711558267),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 30,\n",
       "    'max_depth': 10,\n",
       "    'min_samples_split': 2,\n",
       "    'min_samples_leaf': 10}},\n",
       "  0.9425299325661121),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 10, 'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 3}},\n",
       "  0.5),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 20,\n",
       "    'max_depth': 10,\n",
       "    'min_samples_split': 5,\n",
       "    'min_samples_leaf': 10}},\n",
       "  0.9357087845718614),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 30,\n",
       "    'max_depth': 10,\n",
       "    'min_samples_split': 2,\n",
       "    'min_samples_leaf': 10}},\n",
       "  0.9391247668892685),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 60,\n",
       "    'max_depth': 5,\n",
       "    'min_samples_split': 10,\n",
       "    'min_samples_leaf': 10}},\n",
       "  0.9393662905015434),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 5,\n",
       "    'max_depth': 5,\n",
       "    'min_samples_split': 10,\n",
       "    'min_samples_leaf': 5}},\n",
       "  0.9143532675867316),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 100,\n",
       "    'max_depth': 15,\n",
       "    'min_samples_split': 2,\n",
       "    'min_samples_leaf': 10}},\n",
       "  0.9419746701914837),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 70,\n",
       "    'max_depth': 15,\n",
       "    'min_samples_split': 5,\n",
       "    'min_samples_leaf': 10}},\n",
       "  0.9416168699183374),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 20,\n",
       "    'max_depth': 20,\n",
       "    'min_samples_split': 5,\n",
       "    'min_samples_leaf': 10}},\n",
       "  0.9367736117405923),\n",
       " ({'model': LogisticRegression(solver='liblinear'),\n",
       "   'params': {'C': 0.1, 'penalty': 'l2', 'max_iter': 1000}},\n",
       "  0.8692881250865598),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 80,\n",
       "    'max_depth': 20,\n",
       "    'min_samples_split': 2,\n",
       "    'min_samples_leaf': 10}},\n",
       "  0.9434199122225502),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 20,\n",
       "    'max_depth': 15,\n",
       "    'min_samples_split': 2,\n",
       "    'min_samples_leaf': 5}},\n",
       "  0.9412320853423818),\n",
       " ({'model': LogisticRegression(solver='liblinear'),\n",
       "   'params': {'C': 10, 'penalty': 'l1', 'max_iter': 1000}},\n",
       "  0.9086149001371071),\n",
       " ({'model': LogisticRegression(solver='liblinear'),\n",
       "   'params': {'C': 0.1, 'penalty': 'l1', 'max_iter': 100}},\n",
       "  0.9012308974255818),\n",
       " ({'model': LogisticRegression(solver='liblinear'),\n",
       "   'params': {'C': 0.5, 'penalty': 'l2', 'max_iter': 100}},\n",
       "  0.9018156435458323),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 5, 'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 5}},\n",
       "  0.5),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 5, 'kernel': 'rbf', 'gamma': 'auto', 'degree': 5}},\n",
       "  0.7049375138184196),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 30,\n",
       "    'max_depth': 10,\n",
       "    'min_samples_split': 5,\n",
       "    'min_samples_leaf': 10}},\n",
       "  0.9404188752402758),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 0.5, 'kernel': 'linear', 'gamma': 'scale', 'degree': 2}},\n",
       "  0.9081830400327405),\n",
       " ({'model': LogisticRegression(solver='liblinear'),\n",
       "   'params': {'C': 10, 'penalty': 'l1', 'max_iter': 100}},\n",
       "  0.9086298522902172),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 100,\n",
       "    'max_depth': 20,\n",
       "    'min_samples_split': 5,\n",
       "    'min_samples_leaf': 1}},\n",
       "  0.9429357896757313),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 0.1, 'kernel': 'rbf', 'gamma': 'auto', 'degree': 2}},\n",
       "  0.7124938278838174),\n",
       " ({'model': LogisticRegression(solver='liblinear'),\n",
       "   'params': {'C': 0.5, 'penalty': 'l1', 'max_iter': 500}},\n",
       "  0.9082440402335414),\n",
       " ({'model': LogisticRegression(solver='liblinear'),\n",
       "   'params': {'C': 5, 'penalty': 'l2', 'max_iter': 500}},\n",
       "  0.9083935617646419),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 0.1, 'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 3}},\n",
       "  0.5),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 5, 'kernel': 'linear', 'gamma': 'scale', 'degree': 2}},\n",
       "  0.9085860472323819),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 1, 'kernel': 'sigmoid', 'gamma': 'scale', 'degree': 5}},\n",
       "  0.4228262146146098)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fefd9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: random_forest\n",
      "Decoded Hyperparameters: {'n_estimators': 29, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 12}\n",
      "Score:  2.467686300814556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abuba\\AppData\\Local\\Temp\\ipykernel_12632\\2727159152.py:82: RuntimeWarning: divide by zero encountered in divide\n",
      "  ratio = np.exp(log_prob_x1) / np.exp(log_prob_x2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "label_encoders = {}\n",
    "for algo_name, algo_dict in space.items():\n",
    "    params_dict = algo_dict['params']\n",
    "    label_encoders[algo_name] = {}\n",
    "    for param_name, param_values in params_dict.items():\n",
    "        if isinstance(param_values[0], str):  # Categorical parameter\n",
    "            le = LabelEncoder()\n",
    "            le.fit(param_values)\n",
    "            label_encoders[algo_name][param_name] = le\n",
    "        else:\n",
    "            label_encoders[algo_name][param_name] = None\n",
    "\n",
    "# Encode hyperparameters\n",
    "def encode_hyperparameters(algo_name, hyperparams):\n",
    "    encoded_hyperparams = []\n",
    "    for param_name, param_value in hyperparams.items():\n",
    "        if label_encoders[algo_name][param_name] is not None:  # Check if parameter is categorical\n",
    "            le = label_encoders[algo_name][param_name]\n",
    "            encoded_value = le.transform([param_value])[0]\n",
    "            encoded_hyperparams.append(encoded_value)\n",
    "        else:\n",
    "            encoded_hyperparams.append(param_value)  # Non-categorical parameter\n",
    "    return encoded_hyperparams\n",
    "\n",
    "# Mapping of model class names to space keys\n",
    "model_name_to_space_key = {\n",
    "    'svc': 'svm',\n",
    "    'randomforestclassifier': 'random_forest',\n",
    "    'logisticregression': 'logistic_regression'\n",
    "}\n",
    "\n",
    "# Encode observations\n",
    "encoded_observations = []\n",
    "for obs in observations:\n",
    "    hyperparams, score = obs\n",
    "    model_class_name = hyperparams['model'].__class__.__name__.lower()\n",
    "    algo_name = model_name_to_space_key[model_class_name]\n",
    "    encoded_hyperparams = encode_hyperparameters(algo_name, hyperparams['params'])\n",
    "    encoded_observations.append(encoded_hyperparams + [score])\n",
    "\n",
    "# Ensuring consistent length by padding with zeros\n",
    "max_length = max(len(obs) for obs in encoded_observations)\n",
    "padded_observations = np.array([obs + [0] * (max_length - len(obs)) for obs in encoded_observations])\n",
    "\n",
    "# Split into two groups X1 (best) and X2 (rest)\n",
    "sorted_observations = sorted(padded_observations, key=lambda x: x[-1], reverse=True)\n",
    "split_index = int(len(sorted_observations) * 0.2)\n",
    "if split_index == 0:\n",
    "    split_index = 1\n",
    "\n",
    "X1 = np.array(sorted_observations[:split_index])\n",
    "X2 = np.array(sorted_observations[split_index:])\n",
    "if X1.ndim == 1:\n",
    "    X1 = X1.reshape(1, -1)\n",
    "if X2.ndim == 1:\n",
    "    X2 = X2.reshape(1, -1)\n",
    "if len(X1) == 0:\n",
    "    X1 = np.array([sorted_observations[0]])\n",
    "if len(X2) == 0:\n",
    "    X2 = np.array([sorted_observations[-1]])\n",
    "\n",
    "def fit_kde(X):\n",
    "    if len(X) < 2:\n",
    "        return None\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=1).fit(X)\n",
    "    return kde\n",
    "\n",
    "kde_x1 = fit_kde(X1)\n",
    "kde_x2 = fit_kde(X2)\n",
    "\n",
    "if kde_x1:\n",
    "    sample_hyperparameters = kde_x1.sample(100)\n",
    "else:\n",
    "    sample_hyperparameters = X1  # Use X1 directly if KDE fitting is not possible\n",
    "\n",
    "if kde_x1 and kde_x2:\n",
    "    log_prob_x1 = kde_x1.score_samples(sample_hyperparameters)\n",
    "    log_prob_x2 = kde_x2.score_samples(sample_hyperparameters)\n",
    "    ratio = np.exp(log_prob_x1) / np.exp(log_prob_x2)\n",
    "else:\n",
    "    ratio = np.zeros(len(sample_hyperparameters))  # Fallback ratio\n",
    "\n",
    "best_hyperparameters = sample_hyperparameters[np.argmin(ratio)]\n",
    "\n",
    "def decode_hyperparameters(encoded_hyperparams, algo_name):\n",
    "    decoded_hyperparams = {}\n",
    "    index = 0\n",
    "    for param_name in space[algo_name]['params']:\n",
    "        if label_encoders[algo_name][param_name] is not None:  # Categorical parameter\n",
    "            le = label_encoders[algo_name][param_name]\n",
    "            decoded_value = le.inverse_transform([int(round(encoded_hyperparams[index]))])[0]\n",
    "            decoded_hyperparams[param_name] = decoded_value\n",
    "            index += 1\n",
    "        else:\n",
    "            decoded_hyperparams[param_name] = int(round(encoded_hyperparams[index]))\n",
    "            index += 1\n",
    "    return decoded_hyperparams\n",
    "\n",
    "def infer_algo_name(encoded_hyperparams):\n",
    "    for algo_name, params_dict in label_encoders.items():\n",
    "        expected_length = sum(len(le.classes_) if le is not None else 1 for le in params_dict.values())\n",
    "        if len(encoded_hyperparams) == expected_length:\n",
    "            return algo_name\n",
    "    return None\n",
    "\n",
    "encoded_hyperparams_without_score = best_hyperparameters[:-1]\n",
    "inferred_algo_name = infer_algo_name(encoded_hyperparams_without_score)\n",
    "if inferred_algo_name is None:\n",
    "    raise ValueError(\"Unable to infer the algorithm from the encoded hyperparameters.\")\n",
    "\n",
    "decoded_hyperparams = decode_hyperparameters(encoded_hyperparams_without_score, inferred_algo_name)\n",
    "\n",
    "print(f\"Algorithm: {inferred_algo_name}\")\n",
    "print(\"Decoded Hyperparameters:\", decoded_hyperparams)\n",
    "print(\"Score: \", best_hyperparameters[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a93db09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: random_forest\n",
      "Decoded Hyperparameters: {'n_estimators': 30, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 6}\n",
      "Score:  0.9397853366414177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Initialize label encoders for categorical parameters\n",
    "label_encoders = {}\n",
    "for algo_name, algo_dict in space.items():\n",
    "    params_dict = algo_dict['params']\n",
    "    label_encoders[algo_name] = {}\n",
    "    for param_name, param_values in params_dict.items():\n",
    "        if isinstance(param_values[0], str):  # Categorical parameter\n",
    "            le = LabelEncoder()\n",
    "            le.fit(param_values)\n",
    "            label_encoders[algo_name][param_name] = le\n",
    "        else:\n",
    "            label_encoders[algo_name][param_name] = None\n",
    "\n",
    "# Encode hyperparameters\n",
    "def encode_hyperparameters(algo_name, hyperparams):\n",
    "    encoded_hyperparams = []\n",
    "    for param_name, param_value in hyperparams.items():\n",
    "        if label_encoders[algo_name][param_name] is not None:  # Check if parameter is categorical\n",
    "            le = label_encoders[algo_name][param_name]\n",
    "            encoded_value = le.transform([param_value])[0]\n",
    "            encoded_hyperparams.append(encoded_value)\n",
    "        else:\n",
    "            encoded_hyperparams.append(param_value)  # Non-categorical parameter\n",
    "    return encoded_hyperparams\n",
    "\n",
    "# Mapping of model class names to space keys\n",
    "model_name_to_space_key = {\n",
    "    'svc': 'svm',\n",
    "    'randomforestclassifier': 'random_forest',\n",
    "    'logisticregression': 'logistic_regression'\n",
    "}\n",
    "\n",
    "# Encode observations\n",
    "encoded_observations = []\n",
    "for obs in observations:\n",
    "    hyperparams, score = obs\n",
    "    model_class_name = hyperparams['model'].__class__.__name__.lower()\n",
    "    algo_name = model_name_to_space_key[model_class_name]\n",
    "    encoded_hyperparams = encode_hyperparameters(algo_name, hyperparams['params'])\n",
    "    encoded_observations.append(encoded_hyperparams + [score])\n",
    "\n",
    "# Ensuring consistent length by padding with zeros\n",
    "max_length = max(len(obs) for obs in encoded_observations)\n",
    "padded_observations = np.array([obs + [0] * (max_length - len(obs)) for obs in encoded_observations])\n",
    "\n",
    "# Split into two groups X1 (best) and X2 (rest)\n",
    "sorted_observations = sorted(padded_observations, key=lambda x: x[-1], reverse=True)\n",
    "split_index = int(len(sorted_observations) * 0.2)\n",
    "if split_index == 0:\n",
    "    split_index = 1\n",
    "\n",
    "X1 = np.array(sorted_observations[:split_index])\n",
    "X2 = np.array(sorted_observations[split_index:])\n",
    "if X1.ndim == 1:\n",
    "    X1 = X1.reshape(1, -1)\n",
    "if X2.ndim == 1:\n",
    "    X2 = X2.reshape(1, -1)\n",
    "if len(X1) == 0:\n",
    "    X1 = np.array([sorted_observations[0]])\n",
    "if len(X2) == 0:\n",
    "    X2 = np.array([sorted_observations[-1]])\n",
    "\n",
    "# Normalize X1 and X2\n",
    "scaler = StandardScaler()\n",
    "X1_normalized = scaler.fit_transform(X1)\n",
    "X2_normalized = scaler.transform(X2)\n",
    "\n",
    "# Fit Kernel Density Estimators\n",
    "def fit_kde(X):\n",
    "    if len(X) < 2:\n",
    "        return None\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=1).fit(X)\n",
    "    return kde\n",
    "\n",
    "kde_x1 = fit_kde(X1_normalized)\n",
    "kde_x2 = fit_kde(X2_normalized)\n",
    "\n",
    "if kde_x1:\n",
    "    sample_hyperparameters_normalized = kde_x1.sample(100)\n",
    "    sample_hyperparameters = scaler.inverse_transform(sample_hyperparameters_normalized)\n",
    "else:\n",
    "    sample_hyperparameters = X1  # Use X1 directly if KDE fitting is not possible\n",
    "\n",
    "if kde_x1 and kde_x2:\n",
    "    log_prob_x1 = kde_x1.score_samples(sample_hyperparameters_normalized)\n",
    "    log_prob_x2 = kde_x2.score_samples(sample_hyperparameters_normalized)\n",
    "    log_ratio = log_prob_x1 - log_prob_x2\n",
    "    ratio = np.exp(log_ratio)\n",
    "else:\n",
    "    ratio = np.zeros(len(sample_hyperparameters))  # Fallback ratio\n",
    "\n",
    "best_hyperparameters = sample_hyperparameters[np.argmin(ratio)]\n",
    "\n",
    "def decode_hyperparameters(encoded_hyperparams, algo_name):\n",
    "    decoded_hyperparams = {}\n",
    "    index = 0\n",
    "    for param_name in space[algo_name]['params']:\n",
    "        if label_encoders[algo_name][param_name] is not None:  # Categorical parameter\n",
    "            le = label_encoders[algo_name][param_name]\n",
    "            decoded_value = le.inverse_transform([int(round(encoded_hyperparams[index]))])[0]\n",
    "            decoded_hyperparams[param_name] = decoded_value\n",
    "            index += 1\n",
    "        else:\n",
    "            decoded_hyperparams[param_name] = int(round(encoded_hyperparams[index]))\n",
    "            index += 1\n",
    "    return decoded_hyperparams\n",
    "\n",
    "def infer_algo_name(encoded_hyperparams):\n",
    "    for algo_name, params_dict in label_encoders.items():\n",
    "        expected_length = sum(len(le.classes_) if le is not None else 1 for le in params_dict.values())\n",
    "        if len(encoded_hyperparams) == expected_length:\n",
    "            return algo_name\n",
    "    return None\n",
    "\n",
    "encoded_hyperparams_without_score = best_hyperparameters[:-1]\n",
    "inferred_algo_name = infer_algo_name(encoded_hyperparams_without_score)\n",
    "if inferred_algo_name is None:\n",
    "    raise ValueError(\"Unable to infer the algorithm from the encoded hyperparameters.\")\n",
    "\n",
    "decoded_hyperparams = decode_hyperparameters(encoded_hyperparams_without_score, inferred_algo_name)\n",
    "\n",
    "print(f\"Algorithm: {inferred_algo_name}\")\n",
    "print(\"Decoded Hyperparameters:\", decoded_hyperparams)\n",
    "print(\"Score: \", best_hyperparameters[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ce9045d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 1/50\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m hyperparams, score \u001b[38;5;241m=\u001b[39m obs\n\u001b[0;32m     13\u001b[0m model_class_name \u001b[38;5;241m=\u001b[39m hyperparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m---> 14\u001b[0m algo_name \u001b[38;5;241m=\u001b[39m model_name_to_space_key[model_class_name]\n\u001b[0;32m     15\u001b[0m encoded_hyperparams \u001b[38;5;241m=\u001b[39m encode_hyperparameters(algo_name, hyperparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     16\u001b[0m encoded_observations\u001b[38;5;241m.\u001b[39mappend(encoded_hyperparams \u001b[38;5;241m+\u001b[39m [score])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'str'"
     ]
    }
   ],
   "source": [
    "curve = []\n",
    "for i in range(50):\n",
    "    model_name_to_class = {\n",
    "        'svc': SVC,\n",
    "        'randomforestclassifier': RandomForestClassifier,\n",
    "        'logisticregression': LogisticRegression\n",
    "    }\n",
    "    # Encode the observations\n",
    "    print(f\"Trial: {i+1}/50\")\n",
    "    encoded_observations = []\n",
    "    for obs in observations:\n",
    "        hyperparams, score = obs\n",
    "        model_class_name = hyperparams['model'].__class__.__name__.lower()\n",
    "        algo_name = model_name_to_space_key[model_class_name]\n",
    "        encoded_hyperparams = encode_hyperparameters(algo_name, hyperparams['params'])\n",
    "        encoded_observations.append(encoded_hyperparams + [score])\n",
    "\n",
    "    # Ensuring consistent length by padding with zeros\n",
    "    max_length = max(len(obs) for obs in encoded_observations)\n",
    "    padded_observations = np.array([obs + [0] * (max_length - len(obs)) for obs in encoded_observations])\n",
    "\n",
    "    # Split into two groups X1 (best) and X2 (rest)\n",
    "    sorted_observations = sorted(padded_observations, key=lambda x: x[-1], reverse=True)\n",
    "    split_index = int(len(sorted_observations) * 0.2)\n",
    "    if split_index == 0:\n",
    "        split_index = 1\n",
    "\n",
    "    X1 = np.array(sorted_observations[:split_index])\n",
    "    X2 = np.array(sorted_observations[split_index:])\n",
    "    if X1.ndim == 1:\n",
    "        X1 = X1.reshape(1, -1)\n",
    "    if X2.ndim == 1:\n",
    "        X2 = X2.reshape(1, -1)\n",
    "    if len(X1) == 0:\n",
    "        X1 = np.array([sorted_observations[0]])\n",
    "    if len(X2) == 0:\n",
    "        X2 = np.array([sorted_observations[-1]])\n",
    "\n",
    "    # Normalize X1 and X2\n",
    "    scaler = StandardScaler()\n",
    "    X1_normalized = scaler.fit_transform(X1)\n",
    "    X2_normalized = scaler.transform(X2)\n",
    "\n",
    "    # Fit Kernel Density Estimators\n",
    "    def fit_kde(X):\n",
    "        if len(X) < 2:\n",
    "            return None\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=1).fit(X)\n",
    "        return kde\n",
    "\n",
    "    kde_x1 = fit_kde(X1_normalized)\n",
    "    kde_x2 = fit_kde(X2_normalized)\n",
    "\n",
    "    if kde_x1:\n",
    "        sample_hyperparameters_normalized = kde_x1.sample(100)\n",
    "        sample_hyperparameters = scaler.inverse_transform(sample_hyperparameters_normalized)\n",
    "    else:\n",
    "        sample_hyperparameters = X1  # Use X1 directly if KDE fitting is not possible\n",
    "\n",
    "    if kde_x1 and kde_x2:\n",
    "        log_prob_x1 = kde_x1.score_samples(sample_hyperparameters_normalized)\n",
    "        log_prob_x2 = kde_x2.score_samples(sample_hyperparameters_normalized)\n",
    "        log_ratio = log_prob_x1 - log_prob_x2\n",
    "        ratio = np.exp(log_ratio)\n",
    "    else:\n",
    "        ratio = np.zeros(len(sample_hyperparameters))  # Fallback ratio\n",
    "\n",
    "    best_hyperparameters = sample_hyperparameters[np.argmin(ratio)]\n",
    "\n",
    "    def decode_hyperparameters(encoded_hyperparams, algo_name):\n",
    "        decoded_hyperparams = {}\n",
    "        index = 0\n",
    "        for param_name in space[algo_name]['params']:\n",
    "            if label_encoders[algo_name][param_name] is not None:  # Categorical parameter\n",
    "                le = label_encoders[algo_name][param_name]\n",
    "                decoded_value = le.inverse_transform([int(round(encoded_hyperparams[index]))])[0]\n",
    "                decoded_hyperparams[param_name] = decoded_value\n",
    "                index += 1\n",
    "            else:\n",
    "                decoded_hyperparams[param_name] = int(round(encoded_hyperparams[index]))\n",
    "                index += 1\n",
    "        return decoded_hyperparams\n",
    "\n",
    "    def infer_algo_name(encoded_hyperparams):\n",
    "        for algo_name, params_dict in label_encoders.items():\n",
    "            expected_length = sum(len(le.classes_) if le is not None else 1 for le in params_dict.values())\n",
    "            if len(encoded_hyperparams) == expected_length:\n",
    "                return algo_name\n",
    "        return None\n",
    "\n",
    "    encoded_hyperparams_without_score = best_hyperparameters[:-1]\n",
    "    inferred_algo_name = infer_algo_name(encoded_hyperparams_without_score)\n",
    "    if inferred_algo_name is None:\n",
    "        raise ValueError(\"Unable to infer the algorithm from the encoded hyperparameters.\")\n",
    "\n",
    "    decoded_hyperparams = decode_hyperparameters(encoded_hyperparams_without_score, inferred_algo_name)\n",
    "    \n",
    "    observations.append(({\"model\": inferred_algo_name, \"params\": decoded_hyperparams}, best_hyperparameters[-1]))\n",
    "    curve.append((i+1, best_hyperparameters[-1]))\n",
    "    print(best_hyperparameters[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5622a16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 1/50\n",
      "Model Class Name: svc\n",
      "Model Class Name: randomforestclassifier\n",
      "Model Class Name: logisticregression\n",
      "Model Class Name: randomforestclassifier\n",
      "Model Class Name: svc\n",
      "Model Class Name: logisticregression\n",
      "Model Class Name: svc\n",
      "Model Class Name: randomforestclassifier\n",
      "Model Class Name: svc\n",
      "Model Class Name: randomforestclassifier\n",
      "Model Class Name: logisticregression\n",
      "Model Class Name: svc\n",
      "Model Class Name: svc\n",
      "Model Class Name: randomforestclassifier\n",
      "Model Class Name: randomforestclassifier\n",
      "Model Class Name: svc\n",
      "Model Class Name: logisticregression\n",
      "Model Class Name: randomforestclassifier\n",
      "Model Class Name: logisticregression\n",
      "Model Class Name: svc\n",
      "Model Class Name: svc\n",
      "Model Class Name: randomforestclassifier\n",
      "Model Class Name: logisticregression\n",
      "Model Class Name: randomforestclassifier\n",
      "Model Class Name: logisticregression\n",
      "Model Class Name: logisticregression\n",
      "Model Class Name: svc\n",
      "Model Class Name: randomforestclassifier\n",
      "Model Class Name: svc\n",
      "Model Class Name: randomforestclassifier\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown model name: random_forest",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m hyperparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_name_to_space_key:\n\u001b[1;32m---> 18\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown model name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m     model_class_name \u001b[38;5;241m=\u001b[39m model_name\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown model name: random_forest"
     ]
    }
   ],
   "source": [
    "curve = []\n",
    "for i in range(50):\n",
    "    model_name_to_space_key = {\n",
    "        'svc': 'svm',\n",
    "        'randomforestclassifier': 'random_forest',\n",
    "        'logisticregression': 'logistic_regression'\n",
    "    }\n",
    "    # Encode the observations\n",
    "    print(f\"Trial: {i+1}/50\")\n",
    "    encoded_observations = []\n",
    "    for obs in observations:\n",
    "        hyperparams, score = obs\n",
    "        \n",
    "        # Ensure hyperparams['model'] is an instance, not a string\n",
    "        if isinstance(hyperparams['model'], str):\n",
    "            model_name = hyperparams['model'].lower()\n",
    "            if model_name not in model_name_to_space_key:\n",
    "                raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "            model_class_name = model_name\n",
    "        else:\n",
    "            model_class_name = hyperparams['model'].__class__.__name__.lower()\n",
    "\n",
    "        print(f\"Model Class Name: {model_class_name}\")  # Print to debug\n",
    "        \n",
    "        if model_class_name not in model_name_to_space_key:\n",
    "            raise ValueError(f\"Unknown model class name: {model_class_name}\")\n",
    "        \n",
    "        algo_name = model_name_to_space_key[model_class_name]\n",
    "        encoded_hyperparams = encode_hyperparameters(algo_name, hyperparams['params'])\n",
    "        encoded_observations.append(encoded_hyperparams + [score])\n",
    "\n",
    "    # Ensuring consistent length by padding with zeros\n",
    "    max_length = max(len(obs) for obs in encoded_observations)\n",
    "    padded_observations = np.array([obs + [0] * (max_length - len(obs)) for obs in encoded_observations])\n",
    "\n",
    "    # Split into two groups X1 (best) and X2 (rest)\n",
    "    sorted_observations = sorted(padded_observations, key=lambda x: x[-1], reverse=True)\n",
    "    split_index = int(len(sorted_observations) * 0.2)\n",
    "    if split_index == 0:\n",
    "        split_index = 1\n",
    "\n",
    "    X1 = np.array(sorted_observations[:split_index])\n",
    "    X2 = np.array(sorted_observations[split_index:])\n",
    "    if X1.ndim == 1:\n",
    "        X1 = X1.reshape(1, -1)\n",
    "    if X2.ndim == 1:\n",
    "        X2 = X2.reshape(1, -1)\n",
    "    if len(X1) == 0:\n",
    "        X1 = np.array([sorted_observations[0]])\n",
    "    if len(X2) == 0:\n",
    "        X2 = np.array([sorted_observations[-1]])\n",
    "\n",
    "    # Normalize X1 and X2\n",
    "    scaler = StandardScaler()\n",
    "    X1_normalized = scaler.fit_transform(X1)\n",
    "    X2_normalized = scaler.transform(X2)\n",
    "\n",
    "    # Fit Kernel Density Estimators\n",
    "    def fit_kde(X):\n",
    "        if len(X) < 2:\n",
    "            return None\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=1).fit(X)\n",
    "        return kde\n",
    "\n",
    "    kde_x1 = fit_kde(X1_normalized)\n",
    "    kde_x2 = fit_kde(X2_normalized)\n",
    "\n",
    "    if kde_x1:\n",
    "        sample_hyperparameters_normalized = kde_x1.sample(100)\n",
    "        sample_hyperparameters = scaler.inverse_transform(sample_hyperparameters_normalized)\n",
    "    else:\n",
    "        sample_hyperparameters = X1  # Use X1 directly if KDE fitting is not possible\n",
    "\n",
    "    if kde_x1 and kde_x2:\n",
    "        log_prob_x1 = kde_x1.score_samples(sample_hyperparameters_normalized)\n",
    "        log_prob_x2 = kde_x2.score_samples(sample_hyperparameters_normalized)\n",
    "        log_ratio = log_prob_x1 - log_prob_x2\n",
    "        ratio = np.exp(log_ratio)\n",
    "    else:\n",
    "        ratio = np.zeros(len(sample_hyperparameters))  # Fallback ratio\n",
    "\n",
    "    best_hyperparameters = sample_hyperparameters[np.argmin(ratio)]\n",
    "\n",
    "    def decode_hyperparameters(encoded_hyperparams, algo_name):\n",
    "        decoded_hyperparams = {}\n",
    "        index = 0\n",
    "        for param_name in space[algo_name]['params']:\n",
    "            if label_encoders[algo_name][param_name] is not None:  # Categorical parameter\n",
    "                le = label_encoders[algo_name][param_name]\n",
    "                decoded_value = le.inverse_transform([int(round(encoded_hyperparams[index]))])[0]\n",
    "                decoded_hyperparams[param_name] = decoded_value\n",
    "                index += 1\n",
    "            else:\n",
    "                decoded_hyperparams[param_name] = int(round(encoded_hyperparams[index]))\n",
    "                index += 1\n",
    "        return decoded_hyperparams\n",
    "\n",
    "    def infer_algo_name(encoded_hyperparams):\n",
    "        for algo_name, params_dict in label_encoders.items():\n",
    "            expected_length = sum(len(le.classes_) if le is not None else 1 for le in params_dict.values())\n",
    "            if len(encoded_hyperparams) == expected_length:\n",
    "                return algo_name\n",
    "        return None\n",
    "\n",
    "    encoded_hyperparams_without_score = best_hyperparameters[:-1]\n",
    "    inferred_algo_name = infer_algo_name(encoded_hyperparams_without_score)\n",
    "    if inferred_algo_name is None:\n",
    "        raise ValueError(\"Unable to infer the algorithm from the encoded hyperparameters.\")\n",
    "\n",
    "    decoded_hyperparams = decode_hyperparameters(encoded_hyperparams_without_score, inferred_algo_name)\n",
    "    \n",
    "    observations.append(({\"model\": hyperparams['model'], \"params\": decoded_hyperparams}, best_hyperparameters[-1]))\n",
    "    curve.append((i+1, best_hyperparameters[-1]))\n",
    "    print(best_hyperparameters[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6d2a3b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 1, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 2}},\n",
       "  0.734273494695685),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 70,\n",
       "    'max_depth': 10,\n",
       "    'min_samples_split': 10,\n",
       "    'min_samples_leaf': 10}},\n",
       "  0.942509863592394),\n",
       " ({'model': LogisticRegression(solver='liblinear'),\n",
       "   'params': {'C': 1, 'penalty': 'l2', 'max_iter': 100}},\n",
       "  0.9060991311173543),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 60,\n",
       "    'max_depth': 15,\n",
       "    'min_samples_split': 10,\n",
       "    'min_samples_leaf': 1}},\n",
       "  0.9406362661286103),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 5, 'kernel': 'sigmoid', 'gamma': 'auto', 'degree': 5}},\n",
       "  0.5),\n",
       " ({'model': LogisticRegression(solver='liblinear'),\n",
       "   'params': {'C': 1, 'penalty': 'l2', 'max_iter': 100}},\n",
       "  0.9060991311173543),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 10, 'kernel': 'sigmoid', 'gamma': 'scale', 'degree': 2}},\n",
       "  0.5175927507457941),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 50,\n",
       "    'max_depth': 5,\n",
       "    'min_samples_split': 5,\n",
       "    'min_samples_leaf': 10}},\n",
       "  0.9388287139239114),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 1, 'kernel': 'linear', 'gamma': 'auto', 'degree': 2}},\n",
       "  0.9084365957947144),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 20,\n",
       "    'max_depth': 15,\n",
       "    'min_samples_split': 2,\n",
       "    'min_samples_leaf': 1}},\n",
       "  0.9352620885804758),\n",
       " ({'model': LogisticRegression(solver='liblinear'),\n",
       "   'params': {'C': 0.5, 'penalty': 'l2', 'max_iter': 1000}},\n",
       "  0.9018156435458323),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 10, 'kernel': 'rbf', 'gamma': 'auto', 'degree': 3}},\n",
       "  0.7039081283371149),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 0.5, 'kernel': 'linear', 'gamma': 'scale', 'degree': 4}},\n",
       "  0.9081905161092955),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 50,\n",
       "    'max_depth': 10,\n",
       "    'min_samples_split': 5,\n",
       "    'min_samples_leaf': 5}},\n",
       "  0.94322882862347),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 5,\n",
       "    'max_depth': 20,\n",
       "    'min_samples_split': 2,\n",
       "    'min_samples_leaf': 5}},\n",
       "  0.922106798426596),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 10, 'kernel': 'rbf', 'gamma': 'scale', 'degree': 3}},\n",
       "  0.8496306921653076),\n",
       " ({'model': LogisticRegression(solver='liblinear'),\n",
       "   'params': {'C': 0.5, 'penalty': 'l2', 'max_iter': 1000}},\n",
       "  0.9018156435458323),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 50,\n",
       "    'max_depth': 20,\n",
       "    'min_samples_split': 2,\n",
       "    'min_samples_leaf': 5}},\n",
       "  0.9457648768972401),\n",
       " ({'model': LogisticRegression(solver='liblinear'),\n",
       "   'params': {'C': 1, 'penalty': 'l2', 'max_iter': 100}},\n",
       "  0.9060991311173543),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 0.5, 'kernel': 'linear', 'gamma': 'scale', 'degree': 5}},\n",
       "  0.9081979921858505),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 0.1, 'kernel': 'linear', 'gamma': 'scale', 'degree': 5}},\n",
       "  0.9072574785020103),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 20,\n",
       "    'max_depth': 20,\n",
       "    'min_samples_split': 10,\n",
       "    'min_samples_leaf': 5}},\n",
       "  0.9400893671243911),\n",
       " ({'model': LogisticRegression(solver='liblinear'),\n",
       "   'params': {'C': 0.5, 'penalty': 'l2', 'max_iter': 500}},\n",
       "  0.9018156435458323),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 5,\n",
       "    'max_depth': 5,\n",
       "    'min_samples_split': 2,\n",
       "    'min_samples_leaf': 5}},\n",
       "  0.9097074459208025),\n",
       " ({'model': LogisticRegression(solver='liblinear'),\n",
       "   'params': {'C': 10, 'penalty': 'l2', 'max_iter': 1000}},\n",
       "  0.9088398833680879),\n",
       " ({'model': LogisticRegression(solver='liblinear'),\n",
       "   'params': {'C': 10, 'penalty': 'l1', 'max_iter': 500}},\n",
       "  0.9086149001371071),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 5, 'kernel': 'linear', 'gamma': 'scale', 'degree': 4}},\n",
       "  0.908593523308937),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 40,\n",
       "    'max_depth': 20,\n",
       "    'min_samples_split': 5,\n",
       "    'min_samples_leaf': 5}},\n",
       "  0.9403128783932788),\n",
       " ({'model': SVC(gamma='auto', probability=True),\n",
       "   'params': {'C': 10, 'kernel': 'sigmoid', 'gamma': 'scale', 'degree': 2}},\n",
       "  0.45652815744435876),\n",
       " ({'model': RandomForestClassifier(),\n",
       "   'params': {'n_estimators': 40,\n",
       "    'max_depth': 15,\n",
       "    'min_samples_split': 2,\n",
       "    'min_samples_leaf': 10}},\n",
       "  0.9374301046087746),\n",
       " ({'model': 'random_forest',\n",
       "   'params': {'n_estimators': 39,\n",
       "    'max_depth': 22,\n",
       "    'min_samples_split': 1,\n",
       "    'min_samples_leaf': 3}},\n",
       "  0.9337183042930185)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
